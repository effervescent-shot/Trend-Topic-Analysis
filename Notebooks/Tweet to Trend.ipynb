{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-08-31_tweetsevenmorebasic.csv',\n",
       " 'tweets',\n",
       " 'save',\n",
       " 'all_trends_world.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"../Data\"\n",
    "TWEETS_PATH = os.path.join(DATA_DIR, 'tweets')\n",
    "TREND_PATH = os.path.join(DATA_DIR, 'all_trends_world.csv')\n",
    "SAVE_PATH = os.path.join(DATA_DIR, 'save')\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_case_split(onegram):\n",
    "    match_list = []\n",
    "    for identifier in set(onegram):    \n",
    "        matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "        match_list += [m.group(0) for m in matches]\n",
    "    \n",
    "    return match_list\n",
    "        \n",
    "def onegram_augment(onegram):\n",
    "    \n",
    "    onegram = set(onegram)\n",
    "    onegram_up = set([gram.upper() for gram in onegram])\n",
    "    onegram_lower = set([gram.lower() for gram in onegram])\n",
    "    \n",
    "    nohash = set([re.sub('#','', gram) for gram in onegram])\n",
    "    nohash_up = set([gram.upper() for gram in nohash])\n",
    "    nohash_lower = set([gram.lower() for gram in nohash])\n",
    "    \n",
    "    camelCase = camel_case_split(nohash) \n",
    "    camelSplit = set()\n",
    "    if len(camelCase) !=0 :\n",
    "        cc_up = [gram.upper() for gram in camelCase]\n",
    "        cc_lower = [gram.lower() for gram in camelCase]\n",
    "\n",
    "        ccHashed = set(['#'+gram for gram in camelCase])\n",
    "        ccHashed_up = set(['#'+gram for gram in cc_up])\n",
    "        ccHashed_lower = set(['#'+gram for gram in cc_lower])\n",
    "        \n",
    "        ccHashJoined = set(['#'.join(camelCase)])\n",
    "        ccHashJoined_up = set(['#'.join(cc_up)])\n",
    "        ccHashJoined_lower = set(['#'.join(cc_lower)])\n",
    "        \n",
    "        \n",
    "        if len(camelCase) > 1:\n",
    "            camelSplit = camelSplit.union(set([' '.join(camelCase)]), \n",
    "                                          set([' '.join(cc_up)]), set([' '.join(cc_lower)]))\n",
    "        \n",
    "        camelCase = set().union(ccHashed, ccHashed_up, ccHashed_lower,\n",
    "                        ccHashJoined_up, ccHashJoined_lower, ccHashJoined)\n",
    "    \n",
    "    return (onegram.union(onegram_up,onegram_lower, nohash,nohash_up,nohash_lower,camelCase), camelSplit)\n",
    "\n",
    "\n",
    "def nonegram_augment(nonegram):\n",
    "    nonegram = set(nonegram)\n",
    "    nonegram_up = set([gram.upper() for gram in nonegram])\n",
    "    nonegram_lower = set([gram.lower() for gram in nonegram])\n",
    "    \n",
    "    return nonegram.union(nonegram_up, nonegram_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_trends(text, onegram_trend_set, nonegram_trend_set):\n",
    "    try:\n",
    "        tokens = text.split(' ')\n",
    "        trend_set = set()\n",
    "        \n",
    "        ####### Match not only the onegram but with augmented set of it  #########\n",
    "        for onegram, onegram_aug in onegram_trend_set.items():\n",
    "            onegram_match = set(tokens).intersection(onegram_aug) \n",
    "#             print(onegram_augmented)\n",
    "#             print(tokens)\n",
    "#             print(camel_split)\n",
    "            if len(onegram_match)!= 0:\n",
    "                trend_set.add(onegram)\n",
    "        \n",
    "        ####### Match not only the nonegram but with augmented set of it  #########\n",
    "#         for nonegram, nonegram_aug in nonegram_trend_set.items():\n",
    "#             others = set([other for other in nonegram_aug if (\" \" + other + \" \") in (\" \" + text +\" \")])\n",
    "#             if len(others)!=0:\n",
    "#                 trend_set.add(nonegram)\n",
    "\n",
    "        return trend_set\n",
    "    \n",
    "    except:\n",
    "        print(text)\n",
    "        return set()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_trend_set(df, trend_col):\n",
    "    \n",
    "    non_list_cols = [col for col in (df.columns) if col != trend_col ]\n",
    "    df2 = pd.DataFrame(df[trend_col].tolist(), index=[df[col] for col in non_list_cols])\\\n",
    "                    .stack()\\\n",
    "                    .reset_index(name=trend_col)[non_list_cols+[trend_col]]\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_trend_date_indexed_function(file, candidates):\n",
    "    \n",
    "    tweets_folder =  TWEETS_PATH\n",
    "    save_folder = SAVE_PATH\n",
    "    \n",
    "    df = pd.read_csv('%s/%s' % (tweets_folder, file))\n",
    "    dfs = []\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        df_that_day = pd.DataFrame(df)\n",
    "        trends_that_day = set(trends[trends.date == candidate]['name'])\n",
    "        \n",
    "        if (len(trends_that_day) == 0):\n",
    "            print('trends for %s not found!' % candidate)\n",
    "            continue\n",
    "\n",
    "        ################################### AUGMENT TREND SETS ############################################\n",
    "        trends_that_day_onegrams = set([trend for trend in trends_that_day if len(trend.split(' ')) == 1])\n",
    "        onegram_trend_set = dict()\n",
    "        camel_split_set = dict()\n",
    "        for k in trends_that_day_onegrams:\n",
    "            v1, v2 = onegram_augment([k])\n",
    "            onegram_trend_set[k] = v1\n",
    "            if len(v2)!=0:\n",
    "                camel_split_set[k] = v2\n",
    "            \n",
    "            \n",
    "        trends_that_day_nonegrams = trends_that_day - trends_that_day_onegrams\n",
    "        nonegram_trend_set = dict((k, nonegram_augment([k])) for k in trends_that_day_nonegrams )\n",
    "        #nonegram_trend_set.update(camel_split_set)\n",
    "        \n",
    "        ################################### APPLY TREND INDEX #############################################\n",
    "        \n",
    "        df_that_day['trends'] = df_that_day.text.apply( lambda x: \n",
    "                                            index_trends(x, onegram_trend_set, nonegram_trend_set))\n",
    "        df_that_day = expand_trend_set(df_that_day, 'trends')\n",
    "        \n",
    "        ###################################################################################################\n",
    "        \n",
    "        df_that_day['trend_date'] = candidate\n",
    "        dfs.append(df_that_day)\n",
    "        \n",
    "    dfs = pd.concat(dfs)\n",
    "    new_file = file.split('_')[0] + \"_trends.csv\"\n",
    "    dfs.to_csv('%s/%s' % (save_folder, new_file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_trend_date_indexed_parallelized():\n",
    "    \n",
    "    tweets_folder =  TWEETS_PATH\n",
    "    save_folder = SAVE_PATH\n",
    "\n",
    "    files = os.listdir(tweets_folder)\n",
    "    files = [file for file in files if file >= '2019-07-01' and 'csv' in file] # trends only available after this date\n",
    "    pool = mp.Pool(mp.cpu_count() - 2)\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        print('%d / %d - %s' % (i, len(files), file))\n",
    "        date = file.split('_')[0]\n",
    "        that_day = pd.Timestamp(date).date()\n",
    "        one_day_before = that_day - pd.Timedelta(days = 1)\n",
    "        one_day_after = that_day + pd.Timedelta(days = 1)\n",
    "        candidates = [str(that_day), str(one_day_before), str(one_day_after)]\n",
    "        pool.apply_async(prepare_data_trend_date_indexed_function, args=(file, candidates))\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013-07-07'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trend_date_parser(d):\n",
    "    format_in =  \"%Y-%m-%d %X\"\n",
    "    format_out = \"%Y-%m-%d\"\n",
    " \n",
    "    d = datetime.strptime(d, format_in)\n",
    "    return d.strftime(format_out)\n",
    "\n",
    "trend_date_parser(\"2013-07-07 23:36:32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>duration</th>\n",
       "      <th>name</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4173506</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>490.0</td>\n",
       "      <td>#الهلال_الرايد</td>\n",
       "      <td>162430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173507</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>코엑스</td>\n",
       "      <td>10596.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173508</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>100.0</td>\n",
       "      <td>#FoodCPNxTEMPT</td>\n",
       "      <td>99623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173509</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>100.0</td>\n",
       "      <td>#あすかなBonDance</td>\n",
       "      <td>27517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173510</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>100.0</td>\n",
       "      <td>#اكثر_مطعم_تحبه</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174082</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>#Newwieeอยู่นี่</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174083</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>#استعداداتكم_للمدرسه</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174084</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Bill O'Brien</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174085</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>#ourflowerkai</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174086</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>#مها_الصعيري</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  duration                  name    volume\n",
       "4173506 2019-08-31     490.0        #الهلال_الرايد  162430.0\n",
       "4173507 2019-08-31     190.0                   코엑스   10596.0\n",
       "4173508 2019-08-31     100.0        #FoodCPNxTEMPT   99623.0\n",
       "4173509 2019-08-31     100.0         #あすかなBonDance   27517.0\n",
       "4173510 2019-08-31     100.0       #اكثر_مطعم_تحبه       0.0\n",
       "...            ...       ...                   ...       ...\n",
       "4174082 2019-08-31      30.0       #Newwieeอยู่นี่       0.0\n",
       "4174083 2019-08-31      30.0  #استعداداتكم_للمدرسه       0.0\n",
       "4174084 2019-08-31      30.0          Bill O'Brien       0.0\n",
       "4174085 2019-08-31      30.0         #ourflowerkai       0.0\n",
       "4174086 2019-08-31      30.0          #مها_الصعيري       0.0\n",
       "\n",
       "[581 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends = pd.read_csv(TREND_PATH, parse_dates=['date'], date_parser=trend_date_parser)\n",
    "tr31 = set(trends[trends.date == '2019-08-31']['name'])\n",
    "trends[trends.date == '2019-08-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('%s/%s' % (TWEETS_PATH, '2019-08-31_tweetsevenmorebasic.csv.bz2.bz2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 3 - 2019-09-01_tweetsevenmorebasic.csv.bz2.bz2\n",
      "1 / 3 - 2019-08-30_tweetsevenmorebasic.csv.bz2.bz2\n",
      "2 / 3 - 2019-08-31_tweetsevenmorebasic.csv.bz2.bz2\n",
      "@ConnieSchultz If only they'd focused on domestic terrorism in 2009 after recognizing the problem.  Authorities ann… https://t.co/nhGh9Z2PMc\n",
      "Thalapathians plz concentrate on our tag only #Verithanam   Ithu neraiya peroda Hard work ..Don't spoil it by using… https://t.co/yaew6qrUw4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @_Badassiee: half introvert, half wit the shits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-231615742a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prepare_data_trend_date_indexed_parallelized()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-30bbb33cbb6b>\u001b[0m in \u001b[0;36mprepare_data_trend_date_indexed_parallelized\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prepare_data_trend_date_indexed_parallelized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "onegram = set( [t for t in tr31 if len(t.split(' '))==1 ])\n",
    "onegram.add(\"#EzgiYuceturk\")\n",
    "nonegram = tr31 - onegram\n",
    "\n",
    "onegram_trend_set = dict()\n",
    "camel_split_set = dict()\n",
    "\n",
    "for k in onegram:\n",
    "    v1, v2 = onegram_augment([k])\n",
    "    onegram_trend_set[k] = v1\n",
    "    camel_split_set[k] = v2\n",
    "\n",
    "nonegram_trend_set = dict((k, nonegram_augment([k])) for k in nonegram )\n",
    "nonegram_trend_set.update(camel_split_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#ForzaJuve'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df.text[665])\n",
    "index_trends(\"My life sucks ezgi yuceturk, forzajuve\", onegram_trend_set , nonegram_trend_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
