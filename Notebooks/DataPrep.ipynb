{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import preprocessor as p\n",
    "from preprocessor.api import clean\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lda_test_data',\n",
       " '2019-07-01_trends.csv',\n",
       " 'oo-2019-08-30_trends.csv',\n",
       " '2019-07-02_trends.csv',\n",
       " 'lda_train_data']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"../Data\"\n",
    "TWEETS_PATH = os.path.join(DATA_DIR, 'tweets')\n",
    "TREND_PATH = os.path.join(DATA_DIR, 'trends')\n",
    "SAVE_PATH = os.path.join(DATA_DIR, 'save')\n",
    "STATS_PATH = os.path.join(DATA_DIR, 'stats')\n",
    "os.listdir(SAVE_PATH)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(dfs):\n",
    "    \"\"\"\n",
    "    count how many tweet a trend has on per day\n",
    "    count how many trend a tweet has on per day\n",
    "    \"\"\"\n",
    "    trend_by = dfs.groupby([\"trend_date\",\"trend\"]).agg({\"id\": \"nunique\"}).reset_index()\n",
    "#     per_day = trend_by.groupby('trend_date')['id'].mean()\n",
    "    trend_by.to_csv(os.path.join(STATS_PATH, \"tweetMatch_per_trend.txt\") , index=True)\n",
    "\n",
    "    \n",
    "    tweet_by = dfs.groupby([\"trend_date\",\"id\"]).agg({\"trend\": \"nunique\"}).reset_index()\n",
    "#     per_day = tweet_by.groupby('trend_date')['id'].mean()\n",
    "    tweet_by.to_csv(os.path.join(STATS_PATH, \"trendMatch_per_tweet.txt\") , index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(dfs):\n",
    "    \"\"\"\n",
    "    clean the digits, punctuation, non-ascii characters\n",
    "    \"\"\"\n",
    "    remove_digits = str.maketrans('', '', string.digits)\n",
    "    exclude = '[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'\n",
    "    non_ascii = re.compile(r'[^\\x00-\\x7F]+')\n",
    "    \n",
    "    dfs['trend'] = dfs['trend'].map(lambda x : x.lower())\n",
    "    dfs['trend'] = dfs['trend'].map(lambda x : x.translate(remove_digits))\n",
    "    dfs['trend'] = dfs['trend'].map(lambda x : re.sub(str(exclude), '', x))    \n",
    "\n",
    "\n",
    "    dfs['text'] = dfs['text'].map(lambda x : x.lower())\n",
    "    dfs['text'] = dfs['text'].map(lambda x : clean(x))\n",
    "    dfs['text'] = dfs['text'].map(lambda x : x.translate(remove_digits))\n",
    "    dfs['text'] = dfs['text'].map(lambda x : re.sub(str(exclude), '', x))    \n",
    "    dfs['text'] = dfs['text'].map(lambda x : re.sub(non_ascii, '', x))\n",
    "    \n",
    "    dfs.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_stats(dfs):\n",
    "    \"\"\"\n",
    "    Plotting stats\n",
    "    #of tweet per topic per day \n",
    "    #of author per topic per day\n",
    "    \"\"\"\n",
    "    tweet_by = dfs.groupby([\"trend_date\",\"trend\"]).agg({\"id\": \"nunique\"}).reset_index()\n",
    "    author_by = dfs.groupby([\"trend_date\",\"trend\"]).agg({\"author_id\": \"nunique\"}).reset_index()\n",
    "    \n",
    "    tweet_by.to_csv(os.path.join(STATS_PATH, \"tweetCount_per_trend.txt\") , index=True)\n",
    "    author_by.to_csv(os.path.join(STATS_PATH, \"authorCount_per_trend.txt\") , index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    \n",
    "    tweets_folder = TWEETS_PATH\n",
    "    save_folder = SAVE_PATH\n",
    "    \n",
    "    files = os.listdir(save_folder)\n",
    "    files = [file for file in files if file >= start and file <= end and 'csv' in file] \n",
    "    dfs = []\n",
    "    \n",
    "    for i, file in enumerate(files):\n",
    "        date = file.split('_')[0]\n",
    "        print('%d / %d - %s - date: %s' % (i, len(files), file, str(date) ))\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(save_folder,file), header=0, usecols=list(range(10)),\n",
    "                         parse_dates=['trend_date'])\n",
    "        df = df[df.lang == \"en\"]\n",
    "        df.drop([\"Unnamed: 0\",\"lang\",\"created_at\",\"match\",\"match_rule\"], inplace=True, axis=1)\n",
    "        df.dropna(inplace=True)\n",
    "        dfs.append(df)\n",
    "        \n",
    "        \n",
    "    dfs = pd.concat(dfs)\n",
    "    \n",
    "    collect_stats(dfs)\n",
    "    clear_text(dfs)\n",
    "    plotting_stats(dfs)\n",
    "    \n",
    "    dfs_train, dfs_test = train_test_split(dfs, test_size=0.00001)    \n",
    "    dfs_train.to_csv(os.path.join(SAVE_PATH, \"lda_train_data\"), index=False)\n",
    "    dfs_test.to_csv(os.path.join(SAVE_PATH, \"lda_test_data\"), index=False)\n",
    "    \n",
    "\n",
    "    return dfs_train, dfs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 3 - 2019-07-01_trends.csv - date: 2019-07-01\n",
      "1 / 3 - 2019-07-02_trends.csv - date: 2019-07-02\n",
      "2 / 3 - 2019-07-03_trends.csv - date: 2019-07-03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101445</th>\n",
       "      <td>556419576</td>\n",
       "      <td>1146486272317362187</td>\n",
       "      <td>rt  exclusive amber confronts michael about jo...</td>\n",
       "      <td>amber</td>\n",
       "      <td>2019-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121693</th>\n",
       "      <td>1123717960252702725</td>\n",
       "      <td>1146174413240512515</td>\n",
       "      <td>rt  loool tommy and mollymae being the only co...</td>\n",
       "      <td>tommy and molly</td>\n",
       "      <td>2019-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210914</th>\n",
       "      <td>788086415456399361</td>\n",
       "      <td>1145891796834226176</td>\n",
       "      <td>rt  looks like michael was the one to hit some...</td>\n",
       "      <td>michael</td>\n",
       "      <td>2019-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111908</th>\n",
       "      <td>227442311</td>\n",
       "      <td>1146516530026504192</td>\n",
       "      <td>rt  anna my riderrrrrerr whats annas instagram...</td>\n",
       "      <td>anna</td>\n",
       "      <td>2019-07-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110185</th>\n",
       "      <td>3861291501</td>\n",
       "      <td>1146517381461753859</td>\n",
       "      <td>rt  nobody instagram</td>\n",
       "      <td>instagramdown</td>\n",
       "      <td>2019-07-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  author_id                   id  \\\n",
       "101445            556419576  1146486272317362187   \n",
       "121693  1123717960252702725  1146174413240512515   \n",
       "210914   788086415456399361  1145891796834226176   \n",
       "111908            227442311  1146516530026504192   \n",
       "110185           3861291501  1146517381461753859   \n",
       "\n",
       "                                                     text            trend  \\\n",
       "101445  rt  exclusive amber confronts michael about jo...            amber   \n",
       "121693  rt  loool tommy and mollymae being the only co...  tommy and molly   \n",
       "210914  rt  looks like michael was the one to hit some...          michael   \n",
       "111908  rt  anna my riderrrrrerr whats annas instagram...             anna   \n",
       "110185                               rt  nobody instagram    instagramdown   \n",
       "\n",
       "       trend_date  \n",
       "101445 2019-07-02  \n",
       "121693 2019-07-03  \n",
       "210914 2019-07-02  \n",
       "111908 2019-07-04  \n",
       "110185 2019-07-04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start =\"2019-07-01\"\n",
    "end = \"2019-09-02\"\n",
    "\n",
    "dfs_train, dfs_test = prepare_data()\n",
    "dfs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1885640413</td>\n",
       "      <td>1145664201295163392</td>\n",
       "      <td>rt  info  do is eected to be released from the...</td>\n",
       "      <td>thatsokayitskyungsoo</td>\n",
       "      <td>2019-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18196</th>\n",
       "      <td>1099108032</td>\n",
       "      <td>1145972126127730688</td>\n",
       "      <td>rt  hows michael gonna keep slagging off amber...</td>\n",
       "      <td>joanna</td>\n",
       "      <td>2019-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92985</th>\n",
       "      <td>3179560841</td>\n",
       "      <td>1146563896297381888</td>\n",
       "      <td>rt  danny to curtis if amy had as much class a...</td>\n",
       "      <td>curtis</td>\n",
       "      <td>2019-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109704</th>\n",
       "      <td>1159992264</td>\n",
       "      <td>1146469205677682688</td>\n",
       "      <td>rt  retweet if you love your country amp ill d...</td>\n",
       "      <td>independeceday</td>\n",
       "      <td>2019-07-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158119</th>\n",
       "      <td>958778077567442945</td>\n",
       "      <td>1146659010541707264</td>\n",
       "      <td>rt  in conclusion whatsapp and instagram are t...</td>\n",
       "      <td>whatsapp</td>\n",
       "      <td>2019-07-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author_id                   id  \\\n",
       "699             1885640413  1145664201295163392   \n",
       "18196           1099108032  1145972126127730688   \n",
       "92985           3179560841  1146563896297381888   \n",
       "109704          1159992264  1146469205677682688   \n",
       "158119  958778077567442945  1146659010541707264   \n",
       "\n",
       "                                                     text  \\\n",
       "699     rt  info  do is eected to be released from the...   \n",
       "18196   rt  hows michael gonna keep slagging off amber...   \n",
       "92985   rt  danny to curtis if amy had as much class a...   \n",
       "109704  rt  retweet if you love your country amp ill d...   \n",
       "158119  rt  in conclusion whatsapp and instagram are t...   \n",
       "\n",
       "                       trend trend_date  \n",
       "699     thatsokayitskyungsoo 2019-07-01  \n",
       "18196                 joanna 2019-07-02  \n",
       "92985                 curtis 2019-07-02  \n",
       "109704        independeceday 2019-07-04  \n",
       "158119              whatsapp 2019-07-04  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(SAVE_PATH,\"2019-09-01_trends.csv\"), header=0, parse_dates=['trend_date'])\n",
    "# df = df[df.lang == \"en\"]\n",
    "# df.drop([\"Unnamed: 0\",\"lang\",\"created_at\",\"match \",\"match rule\"], inplace=True, axis=1)\n",
    "\n",
    "# collect_stats(dfs_train)\n",
    "# clear_text(dfs_train)\n",
    "# plotting_stats(dfs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO CHECK WHAT PERCENTAGE OF THE TWEETS ARE MATCH\n",
    "\n",
    "# df_ana = pd.read_csv(os.path.join(TWEETS_PATH,\"2019-09-01_tweetsevenmorebasic.csv.bz2.bz2\"), header=0)\n",
    "# df_ana.shape\n",
    "# print(df.shape[0]/df_ana.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
